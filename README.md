# LLMDeploymentAndRelated

模型部署工作已经开展了4个月了,从4张A10，T4到200+ H20和A100,部署了十余家家国内厂商的模型，遇到了很多杂乱的问题，用这个md来做一个陆陆续续的总结记录这半年，事情太多太杂，记一笔给以后留下点旧经验。<br>
1.推理框架 vllm<br>
2.打镜像 cuda版本与gpu分配 docker<br>
3.从裸机到容器服务 k8s<br>
4.转发和网络 SSE<br>
5.在线服务设计<br>
6.压力测试和配额管理<br>
7.通信瓶颈与计算瓶颈<br>
8.微调 LlamaFactory<br>
9.不同场景模型的选择与标准


6/24
## 推理框架<br>
工作的突增主要是在2025年过年deepseek出来之后，公司部门要求尽快对deepseek的模型进行评估，在那之前，我只是用组内刚化缘拿到单卡A100在内部平台上进行一些基础推理，那时候用的Llama系列在huggingface提供的transformer包，封装了简单的推理逻辑和基础http service，那时候对streaming,SSE,latency,TTFT都没有什么概念，就是知道反正有一段输入就能有一段输出就够了。作为之前没有参与过模型训练和部署的人来说，有几个关键概念是在部署模型之后才开始理解的。<br>
### Base模型和Instruct微调模型<br>
在最开始huggingface琳琅满目的模型中，自然而言抽取到的是各个模型家族的base模型，在最开始的部署当中，我发现base模型和在chatgpt官网上提供的模型结果天差地别，它很容易陷入死循环，本身的输出也没有解决任何问题，后面它在国内有了一个很贴切的翻译，叫做基座模型，它也组成了我对LLM的初步理解，LLM是在根据Prefill阶段的结果预测下一个Token。一个很简单的例子，在Base模型里发送内容为“你好”的Query,它的返回会是“你好，这是一条深幽的小路，小路上...”这种通顺的话，它本身不会回答问题。与之对应的是Instruct模型，它能够跟踪提问者的问题并针对性的给出响应，让模型能够听懂人类提问的意图，在Instruct模型里发送内容为“你好”的Query，它的返回基本都是“你好！我是blabl模型，今天有什么可以帮你”不再是单纯的续写提问，而是开始了对话。<br>
### 标准输入输出接口<br>
在闭门造车的时候，根本没有想过接口格式问题，就算如此，在最开始的阶段，也和我们下游demo的同事花了一阵子时间在对其接口格式上，目前还比较常用的接口是 completion和chatcompletion接口, Body分别是prompt和message，如果让我来面试部署测试的小伙伴，让他写出一个合法的body会是我最愿意提问的第一个问题，它直接反应了面试者有没有亲手写过query，抄过无数个query之后，Model和Message的格式基本就很难被忘记了。<br>
### 推理框架<br>
很快我们就从闭门造车接入了国际正规，引入了vLLM,这是一个标准化且广泛使用的推理框架，它支持大部分市面上的开源模型，支持张量并行和流水线并行并保持超高的吞吐量，在批量推理的过程里，我推荐参考这篇文章对vLLM的内部原理有一些初步理解。[vLLM and PagedAttention](https://www.runpod.io/blog/introduction-to-vllm-and-pagedattention) 对于部署的用户来说，安装环境，使用docker拉下最新的vLLM的框架，在github vLLM issue里查看模型的支持情况，基本就能起一个服务了。<br>
![image](https://github.com/user-attachments/assets/cf9b8c72-f208-4ff4-8dbb-765a9bfedd58)

## 镜像服务
不同于专款专用，我们需要在机器上运行很多模型来给下游测试，最开始的策略是直接部署到公司内部的推理平台，但很快我们就陷入了debug的死循环，在最初的设计里，下载模型->下载框架->安装依赖->运行，但对于各个厂家提供的模型，这里有非常多的琐碎小事，和平台的框架不匹配，版本不匹配，参数不匹配导致了上线模型时间的不确定性，我们很快就切到了docker环境去避免大部分依赖问题。那两周多加班的经验让我总结了一整套适应目前手头情况的模型流水线，先在裸机上下载模型权重和框架，检测MD5，测**框架内部依赖**与**容器版本不匹配的问题**，再根据平台特性对友商的框架二次封装，上线平台去解决平台内的问题，这种方法很快就保证了onboard模型的稳定性和时效性，从之前每个模型从上线时间不确定，到平均上线时间5天的标准化流程。<br>
几类典型问题<br>
**推理框架有内部依赖** <br>
不少厂家提供的模型是从自己的线上环境拆解的，在他们内网能够正常工作，但出了内网环境很有可能都过不了自检脚本<br>
**平台容器GPU驱动版本与docker版本不匹配** 大部分情况下都是兼容的，但容器driver和cuda版本和宿主机版本有依赖，我也只遇到过一次，这类问题最好的办法就是查阅官方文档，任何二手消息都不能保证正确。 [Nvidia驱动版本](https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html#cuda-major-component-versions) <br>
**平台的NUMA分配问题** 这问题我也只遇到过一次，在一个八卡的Pod里的CPU在合作伙伴的框架里不能正确分配CPU到子node <br>
**平台的httpService问题** 这问题更多是应用层问题，包括http请求的转发，取消，我们在这个过程里也发现了线上超大流量的平台的某个恶性bug。<br>
### 裸机与容器服务
TBD
